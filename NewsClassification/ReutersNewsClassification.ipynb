{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ReutersNewsClassification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MattiaVerticchio/PersonalProjects/blob/master/NewsClassification/ReutersNewsClassification_EN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxeWKevJKMkn",
        "colab_type": "text"
      },
      "source": [
        "# Reuters News Classification\n",
        "> [Italiano]() / **English**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ-GTa2RrrOE",
        "colab_type": "text"
      },
      "source": [
        "> **Abstract**\n",
        ">\n",
        ">  The objective of this notebook is the classification of news by the Reuters agency. We’ll try a Neural Architecture Search approach for Deep Learning applied to Natural Language Processing to analyze strings of text and match them to the proper news category. The benchmark used as a reference is the textbook [Deep Learning with Python by Francois Chollet](https://www.manning.com/books/deep-learning-with-python). The results have accuracy in line with the benchmark, and the target metric, categorical cross-entropy is outperformed by almost 3% within a few minutes of training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtbLBrMJKR5l",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "As the central framework for this task, we’ll use [Auto-Keras](https://arxiv.org/abs/1806.10282), an efficient neural architecture search system developed by DATA Lab at Texas A&M University. It leverages a variant of Bayesian Optimization to guide deep neural network morphism and find a good architecture for our task and dataset, using [Keras](https://keras.io/) and [TensorFlow](https://www.tensorflow.org/) as backend.\n",
        "### Framework Setup\n",
        "First, we have to install it with its dependency, [Keras-Tuner](https://keras-team.github.io/keras-tuner/), which is the hyperparameter optimization library used by [Auto-Keras](https://arxiv.org/abs/1806.10282)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB8AiNrBru5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "pip install -q git+https://github.com/keras-team/keras-tuner.git@1.0.2rc1\n",
        "pip install -q autokeras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iBvLGViKU9G",
        "colab_type": "text"
      },
      "source": [
        "### Imports\n",
        "Now we can import the TensorFlow dataset loading tool and Auto-Keras, as well as NumPy to store images and labels in arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUDTOvHb2HQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "import autokeras as ak\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxtW-SBuKao1",
        "colab_type": "text"
      },
      "source": [
        "### Loading the data\n",
        "The dataset can be now loaded into four NumPy arrays.\n",
        "\n",
        "The data has an offset of 3 units, the first three indices are mapped as follows.\n",
        "```\n",
        "0. Padding\n",
        "1. Start of sequence\n",
        "2. Unknown word\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPLZsQLx2LqR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "928f73f2-21a2-4b2c-ad2d-e12d7916b275"
      },
      "source": [
        "offset = 3\n",
        "(x_train, y_train), (x_test, y_test) =  reuters.load_data(num_words=1000,\n",
        "                                                          index_from=offset)\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "y_test  = y_test.reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzWcDdsr76bO",
        "colab_type": "text"
      },
      "source": [
        "Let’s prepare the dictionary that maps indices to words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zauJ8DUhI9Wm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ef072386-05d7-4f5d-ad07-ae0b576e0635"
      },
      "source": [
        "word_to_id = reuters.get_word_index()\n",
        "word_to_id = {k: (v + offset) for k, v in word_to_id.items()}\n",
        "word_to_id['PADDING'] = 0\n",
        "word_to_id['START_OF_SEQUENCE'] = 1\n",
        "word_to_id['UNKNKOWN'] = 2\n",
        "id_to_word = {value: key for key, value in word_to_id.items()}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srwfsoVz7wuX",
        "colab_type": "text"
      },
      "source": [
        "Now we convert the lists of indices to actual words using a dictionary map. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kTM9qMKLav1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = list(map(lambda sentence: ' '.join(\n",
        "    id_to_word[i] for i in sentence), x_train))\n",
        "x_test = list(map(lambda sentence: ' '.join(\n",
        "    id_to_word[i] for i in sentence), x_test))\n",
        "\n",
        "x_train = np.array(x_train, dtype=np.str)\n",
        "x_test  = np.array(x_test, dtype=np.str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzJyekMOKhve",
        "colab_type": "text"
      },
      "source": [
        "## Building the model\n",
        "`TextClassifier` is the class responsible for the model search. Here I set `max_trials=3` to avoid taking too much time for model exploration, but it can be set to any positive integer. It explores different model architectures by tree-based Bayesian Optimization search. We’ll try only the first three as it’s time-consuming on [Google Colab](https://colab.research.google.com/)’s GPU, where I’m running this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_gZDMRf2z8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = ak.TextClassifier(              # Initialize the text classifier\n",
        "    num_classes=None,                 # Infer the number of classes\n",
        "    multi_label=False,                # Only one output\n",
        "    loss='categorical_crossentropy',  # Select the loss metric\n",
        "    metrics='accuracy',               # Metric to watch\n",
        "    project_name=\"text_classifier\",   # Name of the folder\n",
        "    max_trials=3,                     # Just try three models\n",
        "    directory=None,                   # Automatic folder creation\n",
        "    objective=\"val_loss\",             # Validation set crossentropy\n",
        "    tuner=None,                       # Automatic hyperparameter tuner selection\n",
        "    overwrite=True,                   # Don't load previous experiments\n",
        "    seed=42                           # Set a seed to replicate the experiment\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVTTD1ipKw9H",
        "colab_type": "text"
      },
      "source": [
        "### Neural Architecture Search\n",
        "It’s all ready to start exploring the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22dg4BVh25Yt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "b42bccce-fbab-4fc6-f231-cd9fb9c820f2"
      },
      "source": [
        "clf.fit(                   # Fit the model\n",
        "    x=x_train,             # Training features\n",
        "    y=y_train,             # Training labels\n",
        "    epochs=None,           # Automatic number of epochs\n",
        "    callbacks=None,        # No callbacks\n",
        "    validation_split=0.2,  # Validation data split\n",
        "    validation_data=None   # Use a portion of training data\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 3 Complete [00h 01m 27s]\n",
            "val_loss: 1.2090760469436646\n",
            "\n",
            "Best val_loss So Far: 0.9410121440887451\n",
            "Total elapsed time: 00h 04m 35s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/9\n",
            "281/281 [==============================] - 4s 13ms/step - loss: 2.0264 - accuracy: 0.4977\n",
            "Epoch 2/9\n",
            "281/281 [==============================] - 3s 12ms/step - loss: 1.3888 - accuracy: 0.6778\n",
            "Epoch 3/9\n",
            "281/281 [==============================] - 3s 12ms/step - loss: 1.1446 - accuracy: 0.7269\n",
            "Epoch 4/9\n",
            "281/281 [==============================] - 3s 12ms/step - loss: 0.9995 - accuracy: 0.7621\n",
            "Epoch 5/9\n",
            "281/281 [==============================] - 4s 13ms/step - loss: 0.8872 - accuracy: 0.7867\n",
            "Epoch 6/9\n",
            "281/281 [==============================] - 3s 12ms/step - loss: 0.7960 - accuracy: 0.8042\n",
            "Epoch 7/9\n",
            "281/281 [==============================] - 3s 12ms/step - loss: 0.7154 - accuracy: 0.8219\n",
            "Epoch 8/9\n",
            "281/281 [==============================] - 3s 12ms/step - loss: 0.6371 - accuracy: 0.8390\n",
            "Epoch 9/9\n",
            "281/281 [==============================] - 3s 12ms/step - loss: 0.5867 - accuracy: 0.8488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC2w_ARPK0a8",
        "colab_type": "text"
      },
      "source": [
        "### Model architecture\n",
        "The model found can now be exported. It’s a convolutional multi-layer neural network, and it has the following architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15GDBnRaK3P0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "28ecdd77-ab01-4aec-a651-a46c15759bde"
      },
      "source": [
        "model = clf.export_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 512, 64)           320064    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 508, 256)          82176     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 46)                11822     \n",
            "_________________________________________________________________\n",
            "classification_head_1 (Softm (None, 46)                0         \n",
            "=================================================================\n",
            "Total params: 479,854\n",
            "Trainable params: 479,854\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjgsmnXtK551",
        "colab_type": "text"
      },
      "source": [
        "## Testing the model\n",
        "The benchmark chosen for this dataset is the experiment reported in the book [Deep Learning with Python by Francois Chollet](https://www.manning.com/books/deep-learning-with-python).\n",
        "\n",
        "The testing categorical cross-entropy of the benchmark is ~0.96.\n",
        "\n",
        "Let’s now see how our model performs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FTBZ_w0UBCw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0d7f7531-b672-489c-fdc8-1f113277df3b"
      },
      "source": [
        "current  = clf.evaluate(x_test, y_test)\n",
        "previous = 0.9565213431445807\n",
        "\n",
        "improvement = (abs(current[0] - previous) / previous) * 100\n",
        "print(f'The categorical crossentropy improvement is {round(improvement, 1)}%.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 6ms/step - loss: 0.9285 - accuracy: 0.7850\n",
            "The categorical crossentropy improvement is 2.9%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BTStjjCK8On",
        "colab_type": "text"
      },
      "source": [
        "The accuracy of ~0.79 is in line with the previous model. However, we scored a cross-entropy of ~0.93 with only three models explored, outperforming the textbook benchmark by almost 3%.\n",
        "\n",
        "Depending on our hardware and time availability, of course, we could explore even more models for further improvement in the benchmark score.\n",
        "\n",
        "### [**Go back to index >**](https://github.com/MattiaVerticchio/PersonalProjects/blob/master/README_EN.md)"
      ]
    }
  ]
}