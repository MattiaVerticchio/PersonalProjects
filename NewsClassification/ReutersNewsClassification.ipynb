{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ReutersNewsClassification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxeWKevJKMkn",
        "colab_type": "text"
      },
      "source": [
        "# Reuters Dataset\n",
        "\n",
        "\n",
        "\n",
        "> **Abstract**\n",
        ">\n",
        "> \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtbLBrMJKR5l",
        "colab_type": "text"
      },
      "source": [
        "## Framework setup\n",
        "As central framework for this task we’ll use [Auto-Keras](https://arxiv.org/abs/1806.10282), an efficient neural architecture search system developed by DATA Lab at Texas A&M University. It leverages a variant of Bayesian Optimization to guide deep neural network morphism and find a good architecture for our task and dataset, using Keras and TensorFlow as backend.\n",
        "First, we have to install it with its dependency, [Keras-Tuner](https://keras-team.github.io/keras-tuner/), which is the hyperparameter optimization library used by Auto-Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB8AiNrBru5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q git+https://github.com/keras-team/keras-tuner.git@1.0.2rc1 autokeras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iBvLGViKU9G",
        "colab_type": "text"
      },
      "source": [
        "## Imports\n",
        "Now we can import the TensorFlow dataset loading tool and Auto-Keras, as well as plotting tools to examine the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUDTOvHb2HQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import autokeras as ak\n",
        "from tensorflow.keras.datasets import reuters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxtW-SBuKao1",
        "colab_type": "text"
      },
      "source": [
        "## Loading the data\n",
        "The dataset can be now loaded into four NumPy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPLZsQLx2LqR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "33def0a1-cf41-48fc-efff-b954f4bd7c4c"
      },
      "source": [
        "index_offset = 3  # Index offset\n",
        "(x_train, y_train), (x_test, y_test) =  reuters.load_data(num_words=1000, \n",
        "                                                        index_from=index_offset)\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "y_test  = y_test.reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zauJ8DUhI9Wm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e5be5a46-43b4-4cad-e8e2-c2fc9557bdbe"
      },
      "source": [
        "# Prepare the dictionary of index to word.\n",
        "word_to_id = reuters.get_word_index()\n",
        "word_to_id = {k: (v + index_offset) for k, v in word_to_id.items()}\n",
        "word_to_id['PADDING'] = 0\n",
        "word_to_id['START_OF_SEQUENCE'] = 1\n",
        "word_to_id['UNKNKOWN'] = 2\n",
        "id_to_word = {value: key for key, value in word_to_id.items()}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kTM9qMKLav1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the word indices to words.\n",
        "x_train = list(map(lambda sentence: ' '.join(\n",
        "    id_to_word[i] for i in sentence), x_train))\n",
        "x_test = list(map(lambda sentence: ' '.join(\n",
        "    id_to_word[i] for i in sentence), x_test))\n",
        "\n",
        "x_train = np.array(x_train, dtype=np.str)\n",
        "x_test  = np.array(x_test, dtype=np.str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzJyekMOKhve",
        "colab_type": "text"
      },
      "source": [
        "## Building the model\n",
        "`TextClassifier` is the class responsible for model search. Here I set `max_trials=3` to avoid taking too much time for model exploration, but it can be set to any positive integer. It explores different model architectures by tree-based Bayesian Optimization search. We’ll try only the first one as it’s really time consuming on Google Colab’s GPU, where I’m running this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_gZDMRf2z8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = ak.TextClassifier(              # Initialize the text classifier\n",
        "    num_classes=None,                 # Infer the number of classes\n",
        "    multi_label=False,                # Only one output\n",
        "    loss='categorical_crossentropy',  # Select the loss metric\n",
        "    metrics='accuracy',               # Metric to watch\n",
        "    project_name=\"text_classifier\",   # Name of the folder\n",
        "    max_trials=3,                     # Just try three models\n",
        "    directory=None,                   # Automatic folder creation\n",
        "    objective=\"val_loss\",             # Validation set crossentropy\n",
        "    tuner=None,                       # Automatic hyperparameter tuner selection\n",
        "    overwrite=True,                   # Don't load previous experiments\n",
        "    seed=42                           # Set a seed to replicate the experiment\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVTTD1ipKw9H",
        "colab_type": "text"
      },
      "source": [
        "### Neural Architecture Search\n",
        "It’s all ready to start exploring the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22dg4BVh25Yt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "3e950131-2439-4a27-d81b-9999b117315f"
      },
      "source": [
        "clf.fit(                   # Fit the model\n",
        "    x=x_train,             # Training features\n",
        "    y=y_train,             # Training labels\n",
        "    epochs=None,           # Automatic number of epochs\n",
        "    callbacks=None,        # No callbacks\n",
        "    validation_split=0.2,  # Validation data split\n",
        "    validation_data=None   # Use a portion of training data\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 3 Complete [00h 02m 14s]\n",
            "val_loss: 1.2536143064498901\n",
            "\n",
            "Best val_loss So Far: 0.9535587430000305\n",
            "Total elapsed time: 00h 06m 47s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/7\n",
            "281/281 [==============================] - 6s 22ms/step - loss: 2.0264 - accuracy: 0.4977\n",
            "Epoch 2/7\n",
            "281/281 [==============================] - 7s 25ms/step - loss: 1.3889 - accuracy: 0.6778\n",
            "Epoch 3/7\n",
            "281/281 [==============================] - 7s 25ms/step - loss: 1.1435 - accuracy: 0.7267\n",
            "Epoch 4/7\n",
            "281/281 [==============================] - 7s 24ms/step - loss: 0.9961 - accuracy: 0.7625\n",
            "Epoch 5/7\n",
            "281/281 [==============================] - 7s 24ms/step - loss: 0.8839 - accuracy: 0.7857\n",
            "Epoch 6/7\n",
            "281/281 [==============================] - 7s 24ms/step - loss: 0.7920 - accuracy: 0.8078\n",
            "Epoch 7/7\n",
            "281/281 [==============================] - 7s 24ms/step - loss: 0.7107 - accuracy: 0.8249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC2w_ARPK0a8",
        "colab_type": "text"
      },
      "source": [
        "The model found can now be exported, it’s a convolutional multi-layer neural network with the following architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15GDBnRaK3P0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "3f29bdbe-65d1-47f0-cb92-d49dbd48e2ca"
      },
      "source": [
        "model = clf.export_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 512, 64)           320064    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 508, 256)          82176     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 46)                11822     \n",
            "_________________________________________________________________\n",
            "classification_head_1 (Softm (None, 46)                0         \n",
            "=================================================================\n",
            "Total params: 479,854\n",
            "Trainable params: 479,854\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjgsmnXtK551",
        "colab_type": "text"
      },
      "source": [
        "## Testing the model\n",
        "The benchmark chosen for this dataset is the experiment reported on the book [Deep Learning with Python by Francois Chollet](https://www.manning.com/books/deep-learning-with-python). The testing crossentropy of the benchmark is ~0.96.\n",
        "\n",
        "Let’s now test our model on the holdout test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNRVdplb28dJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "163e15cb-1d72-4150-bdff-7a98c83515eb"
      },
      "source": [
        "# Evaluate the best model with testing data.\n",
        "current = clf.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 0.9206 - accuracy: 0.7898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FTBZ_w0UBCw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8a0cbf5c-8b39-43aa-9ceb-8b05770186f5"
      },
      "source": [
        "previous = 0.9565213431445807\n",
        "improvement = (abs(current[0] - previous) / previous) * 100.0\n",
        "\n",
        "print(f'The categorical crossentropy improvement is {round(improvement, 1)}%.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The categorical crossentropy improvement is 3.8%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BTStjjCK8On",
        "colab_type": "text"
      },
      "source": [
        "The accuracy of ~0.79 is in line with the previous model. However, we scored a cross entropy of ~0.92 with only three models explored, outperforming the textbook benchmark by almost 4%.\n",
        "\n",
        "Depending on our hardware and time availability, of course, we could explore even more models for further improvement in the benchmark score.\n",
        "\n",
        "[**Go back to index >**](https://github.com/MattiaVerticchio/PersonalProjects/blob/master/README_EN.md)"
      ]
    }
  ]
}